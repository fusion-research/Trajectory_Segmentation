{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Does This Notebook Do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses an input trajectory dataset to create a __Markov Graph__ as described in section 3.2 of the following paper:\n",
    "* [Discovery of Driving Patterns by Trajectory Segmentation](https://arxiv.org/pdf/1804.08748.pdf)\n",
    "\n",
    "__Input__: a trajectory dataset, where each trajectory is a sequence of record, and each record has the following attributes:\n",
    "* `trip_id` (a string)\n",
    "* `time_step` (an integer)\n",
    "* `speed` (an integer based on km/h)\n",
    "* `acceleration` (a float based on m/s^2)\n",
    "* `heading change` (an integer based on degree)\n",
    "\n",
    "Intput data must be specified in terms of a single csv file named as `graph_trips.csv`, and the input file must be placed inside `/data` directory. \n",
    "\n",
    "__Outputs__: this code generates several csv files as output inside `/prerequisiteFiles` directory :\n",
    "* `transitionsAdv.csv`: this file contains existing state transitions extracted from `graph_trips.csv`\n",
    "* `probsAdv.csv`: this file contains probability of transitions or the Markov graph\n",
    "* `probsRegularized.csv`: this file contains Markov graph after regularization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First step: explore state transitions in an input set of trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_all_transitions():\n",
    "    reader = open('data/graph_trips.csv', 'r')\n",
    "    writer = open('prerequisiteFiles/transitionsAdv.csv', 'w')\n",
    "\n",
    "    transitions = {}\n",
    "    print ('Started to discover transitions...')\n",
    "\n",
    "    prevLine = ''\n",
    "    crntLine  = ''\n",
    "    header = True\n",
    "    n_trajectories = set()\n",
    "    \n",
    "    # obtain and count all transitions\n",
    "    for line in reader:\n",
    "        line = line.replace('\\r','').replace('\\n','')\n",
    "\n",
    "        if header: # skip the header line\n",
    "            header = False\n",
    "            continue\n",
    "\n",
    "        if crntLine == '':\n",
    "            crntLine = line\n",
    "            continue\n",
    "\n",
    "        prevLine = crntLine\n",
    "        crntLine = line\n",
    "\n",
    "        cParts = prevLine.split(',')\n",
    "        nParts = crntLine.split(',')\n",
    "        \n",
    "        n_trajectories.add(cParts[0])\n",
    "\n",
    "        try:\n",
    "            if cParts[0] == nParts[0]:\n",
    "                cTime = int(cParts[1])\n",
    "                nTime = int(nParts[1])\n",
    "\n",
    "                cState = cParts[2] + \"&\" + cParts[3] + \"&\" + cParts[4]  # Speed&Acc&Angle\n",
    "                nState = nParts[2] + \"&\" + nParts[3] + \"&\" + nParts[4]  # Speed&Acc&Angle\n",
    "\n",
    "                if nTime - cTime == 1:\n",
    "\n",
    "                    destin = {}\n",
    "\n",
    "                    if cState in transitions:\n",
    "                        destin = transitions[cState]\n",
    "\n",
    "                    if nState in destin:\n",
    "                        destin[nState] = destin[nState] + 1\n",
    "                    else:\n",
    "                        destin[nState] = 1\n",
    "\n",
    "                    transitions[cState] = destin\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # write transitions into output file\n",
    "    print ('Started to write transitions...')\n",
    "    n_trans = 0\n",
    "    for f_state in transitions:\n",
    "        trans = transitions[f_state]\n",
    "        for s_state in trans:\n",
    "            writer.write(str(f_state) + ',' + str(s_state) + ',' + str(trans[s_state]) + '\\n')\n",
    "            n_trans += 1\n",
    "\n",
    "    writer.close()\n",
    "    print ('Discovered {} transitions in {} trajectories!'.format(n_trans, len(n_trajectories)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second step: obtain state transition probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_transition_probabilities():\n",
    "\n",
    "    print ('Started to compute probability values ...')\n",
    "\n",
    "    # set Acceleration bin size\n",
    "    accelNormalizationFactor = 0.25\n",
    "\n",
    "    # 0: Reading transition raw values and simplify states by normalizing them using normalization factors (if any)\n",
    "    reader = open('prerequisiteFiles/transitionsAdv.csv', 'r')\n",
    "    stateTransitionFreq = {}\n",
    "    for line in reader:\n",
    "        try:\n",
    "            parts = line.replace('\\r','').replace('\\n','').split(',')\n",
    "\n",
    "            spdAccAngle = parts[0].split('&')\n",
    "            crntSpeed = int(float(spdAccAngle[0]))\n",
    "            crntAccel = np.round(float(spdAccAngle[1])/accelNormalizationFactor) * accelNormalizationFactor\n",
    "            crntAngle = int(spdAccAngle[2])\n",
    "\n",
    "            spdAccAngle = parts[1].split('&')\n",
    "            nxtSpeed = int(float(spdAccAngle[0]))\n",
    "            nxtAccel = np.round(float(spdAccAngle[1])/accelNormalizationFactor) * accelNormalizationFactor\n",
    "            nxtAngle = int(spdAccAngle[2])\n",
    "\n",
    "            trans = '{}&{}&{},{}&{}&{}'.format(crntSpeed,crntAccel, crntAngle,nxtSpeed,nxtAccel,nxtAngle)\n",
    "\n",
    "            if trans in stateTransitionFreq:\n",
    "                stateTransitionFreq[trans] = stateTransitionFreq[trans] + int(parts[2])\n",
    "            else:\n",
    "                stateTransitionFreq[trans] = int(parts[2])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "    # 1: Obtain frequency of each state\n",
    "    count = {}\n",
    "    for states in stateTransitionFreq:\n",
    "        parts = states.split(',')\n",
    "\n",
    "        if parts[0] != parts[1]:\n",
    "            if parts[0] in count:\n",
    "                count[parts[0]] = count[parts[0]] + stateTransitionFreq[states]\n",
    "            else:\n",
    "                count[parts[0]] = stateTransitionFreq[states]\n",
    "\n",
    "\n",
    "    # 2: calculate probability for state transitions\n",
    "    probs = {}\n",
    "    for states in stateTransitionFreq:\n",
    "        parts = states.split(',')\n",
    "\n",
    "        probsForThisState = {}\n",
    "        if parts[0] in probs:\n",
    "            probsForThisState = probs[parts[0]]\n",
    "\n",
    "        if parts[0] != parts[1]:\n",
    "            probsForThisState[parts[1]] = float(stateTransitionFreq[states])/count[parts[0]]\n",
    "        elif float(parts[0].split('&')[1]) == 0:\n",
    "            probsForThisState[parts[1]] = 1.0 # transfer of a state to itself is 1, if acceleration is 0. Otherwise, we should not have no increase/decrease in speed when acceleration is positive/negative\n",
    "\n",
    "        probs[parts[0]] = probsForThisState\n",
    "\n",
    "\n",
    "\n",
    "    # 3: print out probability values!\n",
    "    writer = open('prerequisiteFiles/probsAdv.csv', 'w')\n",
    "    for f_state in probs:\n",
    "        for s_state in probs[f_state]:\n",
    "            writer.write('{},{},{},{}\\n'.format(f_state, s_state, probs[f_state][s_state], count[f_state]))\n",
    "\n",
    "    writer.close()\n",
    "    \n",
    "    print ('All transition probabilities are calculated!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third step: Regularization of probability graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, input):\n",
    "        parts = input.split('&')\n",
    "        self.speed = int(parts[0])\n",
    "        self.accel = float(parts[1])\n",
    "        self.heading = int(parts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wedding_cake_probability_regularization():\n",
    "\n",
    "    maxSpeedThreshold = 3    # increase/decrease by steps of size 1.0\n",
    "    maxAccelThreshold = 0.25 # increase/decrease by steps of size 0.25\n",
    "    maxHeadingThreshold = 6  # Some updates on heading by steps of size 6.0 ==> this is based on Change of Heading instead of abslute heading\n",
    "\n",
    "    influenceFactorForAccel = 2.0 # This is a relative factor regarding the influence of accel v.s speed to calculate distance between original and updated states\n",
    "\n",
    "    state2id = {}\n",
    "    id2state = {}\n",
    "\n",
    "    # 1: load probability values\n",
    "    print ('Started to load probability values...')\n",
    "\n",
    "    probs = {}\n",
    "    regularizedProbs = {}\n",
    "\n",
    "    with open('prerequisiteFiles/probsAdv.csv', 'r') as probatility_file:\n",
    "        for line in probatility_file:\n",
    "            parts = line.split(',')\n",
    "\n",
    "            if not parts[0] in state2id:\n",
    "                s = State(parts[0])\n",
    "                state2id[parts[0]] = len(state2id) + 1\n",
    "                id2state[state2id[parts[0]]] = s\n",
    "            s1 = state2id[parts[0]]\n",
    "\n",
    "            if not parts[1] in state2id:\n",
    "                s = State(parts[1])\n",
    "                state2id[parts[1]] = len(state2id) + 1\n",
    "                id2state[state2id[parts[1]]] = s\n",
    "            s2 = state2id[parts[1]]\n",
    "\n",
    "            trans1 = {}\n",
    "            trans2 = {}\n",
    "\n",
    "            if s1 in probs:\n",
    "                trans1 = probs[s1]\n",
    "                trans2 = regularizedProbs[s1]\n",
    "\n",
    "            trans1[s2] = float(parts[2])\n",
    "            trans2[s2] = float(parts[2])\n",
    "\n",
    "            probs[s1] = trans1\n",
    "            regularizedProbs[s1] = trans2\n",
    "\n",
    "\n",
    "    # 2: Normalize probability values\n",
    "    print ('Started to normalize/regularize probability values...')\n",
    "    n_lines = 0;\n",
    "\n",
    "    for f_state in probs:\n",
    "        n_lines += 1.0\n",
    "        if len(regularizedProbs)%100 == 0:\n",
    "            print ('{0: <12}  #RegularizedStatesWithTransitionsFrom:{1: <10}  #RegularizedStates:{2: <10}'\n",
    "                   .format(str(np.round(n_lines*100.0/len(probs), 2)) + '%', len(regularizedProbs), len(state2id)))\n",
    "\n",
    "        s1 = id2state[f_state]\n",
    "        srcSpeed = s1.speed\n",
    "        srcAccel = s1.accel\n",
    "        srcHead  = s1.heading\n",
    "\n",
    "        for s_state in probs[f_state]:\n",
    "            s2 = id2state[s_state]\n",
    "            dstSpeed = s2.speed\n",
    "            dstAccel = s2.accel\n",
    "            dstHead  = s2.heading\n",
    "\n",
    "            # Regularizing by updating the Source   \n",
    "            for s in range(-maxSpeedThreshold, maxSpeedThreshold+1):\n",
    "                for a in np.arange(-maxAccelThreshold, maxAccelThreshold+0.25, 0.25):\n",
    "                    for h in range(-maxHeadingThreshold, maxHeadingThreshold+6, 6):\n",
    "                        state = '{}&{}&{}'.format(srcSpeed+s, srcAccel+a, srcHead+h)\n",
    "\n",
    "                        ## s*a < 0: change in Speed and Acceleration is not in the same direction\n",
    "                        ## Negative speed doesn't make any sense\n",
    "                        ## Negative change of heading does'nt sound.\n",
    "                        if s*a<0 or srcSpeed+s<0 or srcHead+h<0:\n",
    "                            continue\n",
    "\n",
    "                        if not state in state2id:\n",
    "                            _s = State(state)\n",
    "                            state2id[state] = len(state2id) + 1\n",
    "                            id2state[state2id[state]] = _s\n",
    "                        s3 = state2id[state]\n",
    "\n",
    "                        if s3==f_state or s3==s_state:\n",
    "                            continue\n",
    "\n",
    "                        absoluteDistanceBetweenStates = 1.0 / (np.sqrt(s*s + influenceFactorForAccel*a*a + h*h) + 1) # Adding 1 to further regularize the improvement on probability value\n",
    "                        probAug = probs[f_state][s_state] * absoluteDistanceBetweenStates\n",
    "\n",
    "                        toTheseStates = {}\n",
    "                        if s3 in regularizedProbs:\n",
    "                            toTheseStates = regularizedProbs[s3]\n",
    "\n",
    "                        if s_state in toTheseStates:\n",
    "                            toTheseStates[s_state] = toTheseStates[s_state] + probAug\n",
    "                        else:\n",
    "                            toTheseStates[s_state] = probAug\n",
    "\n",
    "                        # Heuristic: if updated acceleration is zero, let's have self transition with probability as 1\n",
    "                        if srcAccel+a == 0:\n",
    "                            toTheseStates[s3] = 1.0\n",
    "\n",
    "                        regularizedProbs[s3] = toTheseStates\n",
    "\n",
    "\n",
    "            # Regularizing by updating the Destination\n",
    "            for s in range(-maxSpeedThreshold, maxSpeedThreshold+1):\n",
    "                for a in np.arange(-maxAccelThreshold, maxAccelThreshold+0.25, 0.25):\n",
    "                    for h in range(-maxHeadingThreshold, maxHeadingThreshold+6, 6):\n",
    "                        state = '{}&{}&{}'.format(dstSpeed+s, dstAccel+a, dstHead+h)\n",
    "\n",
    "                        ## s*a < 0: change in Speed and Acceleration is not in the same direction\n",
    "                        ## Negative speed doesn't make any sense\n",
    "                        ## Negative change of heading does'nt sound.\n",
    "                        if s*a<0 or dstSpeed+s<0 or dstHead+h<0:\n",
    "                            continue\n",
    "\n",
    "                        if not state in state2id:\n",
    "                            _s = State(state)\n",
    "                            state2id[state] = len(state2id) + 1\n",
    "                            id2state[state2id[state]] = _s\n",
    "                        s3 = state2id[state]\n",
    "\n",
    "                        if s3==f_state or s3==s_state:\n",
    "                            continue\n",
    "\n",
    "                        absoluteDistanceBetweenStates = 1.0/(np.sqrt(s*s + influenceFactorForAccel*a*a + h*h) + 1) # Adding 1 to further regularize the improvement on probability value\n",
    "                        probAug = probs[f_state][s_state] * absoluteDistanceBetweenStates\n",
    "\n",
    "                        toTheseStates = regularizedProbs[f_state]\n",
    "\n",
    "                        if s3 in toTheseStates:\n",
    "                            toTheseStates[s3] = toTheseStates[s3] + probAug\n",
    "                        else:\n",
    "                            toTheseStates[s3] = probAug\n",
    "\n",
    "                        regularizedProbs[f_state] = toTheseStates\n",
    "\n",
    "\n",
    "    # 3: Print out probability values! for analysis purpose \n",
    "    writer = open('prerequisiteFiles/probsRegularized.csv', 'w')\n",
    "    totalRegularizedTransitions = 0\n",
    "\n",
    "    for f_state in regularizedProbs:\n",
    "\n",
    "        sum = 0\n",
    "        for s_state in regularizedProbs[f_state]:\n",
    "            sum += regularizedProbs[f_state][s_state]\n",
    "\n",
    "        if id2state[f_state].accel == 0:\n",
    "            sum -= 1 # We have self transition for this case. Then, need to subtract 1 from that\n",
    "\n",
    "        s1 = '{}&{}&{}'.format(id2state[f_state].speed, id2state[f_state].accel, id2state[f_state].heading)\n",
    "\n",
    "        for s_state in regularizedProbs[f_state]:\n",
    "            s2 = '{}&{}&{}'.format(id2state[s_state].speed, id2state[s_state].accel, id2state[s_state].heading)\n",
    "\n",
    "            if f_state != s_state:\n",
    "                writer.write('{},{},{}\\n'.format(s1, s2, regularizedProbs[f_state][s_state]/sum))\n",
    "            else:\n",
    "                writer.write('{},{},{}\\n'.format(s1, s2, 1.0))\n",
    "\n",
    "            totalRegularizedTransitions += 1\n",
    "\n",
    "    writer.close()\n",
    "    print ('\\nNumber of Regularized Transitions: ', totalRegularizedTransitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Processe of Building Markov Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started to discover transitions...\n",
      "Started to write transitions...\n",
      "Discovered 49443 transitions in 500 trajectories!\n",
      "\n",
      "\n",
      "\n",
      "Started to compute probability values ...\n",
      "All transition probabilities are calculated!\n",
      "\n",
      "\n",
      "\n",
      "Started to load probability values...\n",
      "Started to normalize/regularize probability values...\n",
      "0.45%         #RegularizedStatesWithTransitionsFrom:7200        #RegularizedStates:9349      \n",
      "3.97%         #RegularizedStatesWithTransitionsFrom:7700        #RegularizedStates:12303     \n",
      "3.98%         #RegularizedStatesWithTransitionsFrom:7700        #RegularizedStates:12303     \n",
      "15.37%        #RegularizedStatesWithTransitionsFrom:8700        #RegularizedStates:15167     \n",
      "15.39%        #RegularizedStatesWithTransitionsFrom:8700        #RegularizedStates:15167     \n",
      "15.4%         #RegularizedStatesWithTransitionsFrom:8700        #RegularizedStates:15167     \n",
      "15.41%        #RegularizedStatesWithTransitionsFrom:8700        #RegularizedStates:15167     \n",
      "15.43%        #RegularizedStatesWithTransitionsFrom:8700        #RegularizedStates:15167     \n",
      "15.44%        #RegularizedStatesWithTransitionsFrom:8700        #RegularizedStates:15167     \n",
      "17.07%        #RegularizedStatesWithTransitionsFrom:8800        #RegularizedStates:15464     \n",
      "22.38%        #RegularizedStatesWithTransitionsFrom:9100        #RegularizedStates:16138     \n",
      "24.58%        #RegularizedStatesWithTransitionsFrom:9500        #RegularizedStates:16420     \n",
      "24.59%        #RegularizedStatesWithTransitionsFrom:9500        #RegularizedStates:16420     \n",
      "24.61%        #RegularizedStatesWithTransitionsFrom:9500        #RegularizedStates:16420     \n",
      "49.41%        #RegularizedStatesWithTransitionsFrom:12100       #RegularizedStates:18422     \n",
      "49.42%        #RegularizedStatesWithTransitionsFrom:12100       #RegularizedStates:18422     \n",
      "49.44%        #RegularizedStatesWithTransitionsFrom:12100       #RegularizedStates:18422     \n",
      "49.45%        #RegularizedStatesWithTransitionsFrom:12100       #RegularizedStates:18422     \n",
      "49.47%        #RegularizedStatesWithTransitionsFrom:12100       #RegularizedStates:18422     \n",
      "50.52%        #RegularizedStatesWithTransitionsFrom:12200       #RegularizedStates:18460     \n",
      "52.76%        #RegularizedStatesWithTransitionsFrom:12500       #RegularizedStates:18575     \n",
      "52.77%        #RegularizedStatesWithTransitionsFrom:12500       #RegularizedStates:18575     \n",
      "56.64%        #RegularizedStatesWithTransitionsFrom:13100       #RegularizedStates:18752     \n",
      "56.66%        #RegularizedStatesWithTransitionsFrom:13100       #RegularizedStates:18752     \n",
      "56.67%        #RegularizedStatesWithTransitionsFrom:13100       #RegularizedStates:18752     \n",
      "56.69%        #RegularizedStatesWithTransitionsFrom:13100       #RegularizedStates:18752     \n",
      "56.7%         #RegularizedStatesWithTransitionsFrom:13100       #RegularizedStates:18752     \n",
      "56.71%        #RegularizedStatesWithTransitionsFrom:13100       #RegularizedStates:18752     \n",
      "60.56%        #RegularizedStatesWithTransitionsFrom:14000       #RegularizedStates:19152     \n",
      "60.57%        #RegularizedStatesWithTransitionsFrom:14000       #RegularizedStates:19152     \n",
      "60.59%        #RegularizedStatesWithTransitionsFrom:14000       #RegularizedStates:19152     \n",
      "60.6%         #RegularizedStatesWithTransitionsFrom:14000       #RegularizedStates:19152     \n",
      "61.97%        #RegularizedStatesWithTransitionsFrom:14400       #RegularizedStates:19329     \n",
      "61.98%        #RegularizedStatesWithTransitionsFrom:14400       #RegularizedStates:19329     \n",
      "65.53%        #RegularizedStatesWithTransitionsFrom:15000       #RegularizedStates:19476     \n",
      "65.54%        #RegularizedStatesWithTransitionsFrom:15000       #RegularizedStates:19476     \n",
      "66.16%        #RegularizedStatesWithTransitionsFrom:15100       #RegularizedStates:19497     \n",
      "66.17%        #RegularizedStatesWithTransitionsFrom:15100       #RegularizedStates:19497     \n",
      "66.19%        #RegularizedStatesWithTransitionsFrom:15100       #RegularizedStates:19497     \n",
      "72.11%        #RegularizedStatesWithTransitionsFrom:16000       #RegularizedStates:19787     \n",
      "75.69%        #RegularizedStatesWithTransitionsFrom:16600       #RegularizedStates:19883     \n",
      "75.7%         #RegularizedStatesWithTransitionsFrom:16600       #RegularizedStates:19883     \n",
      "75.72%        #RegularizedStatesWithTransitionsFrom:16600       #RegularizedStates:19883     \n",
      "75.73%        #RegularizedStatesWithTransitionsFrom:16600       #RegularizedStates:19883     \n",
      "81.7%         #RegularizedStatesWithTransitionsFrom:17600       #RegularizedStates:20052     \n",
      "81.71%        #RegularizedStatesWithTransitionsFrom:17600       #RegularizedStates:20052     \n",
      "81.73%        #RegularizedStatesWithTransitionsFrom:17600       #RegularizedStates:20052     \n",
      "85.98%        #RegularizedStatesWithTransitionsFrom:18300       #RegularizedStates:20173     \n",
      "85.99%        #RegularizedStatesWithTransitionsFrom:18300       #RegularizedStates:20173     \n",
      "86.01%        #RegularizedStatesWithTransitionsFrom:18300       #RegularizedStates:20173     \n",
      "93.36%        #RegularizedStatesWithTransitionsFrom:19600       #RegularizedStates:20417     \n",
      "93.37%        #RegularizedStatesWithTransitionsFrom:19600       #RegularizedStates:20417     \n",
      "93.38%        #RegularizedStatesWithTransitionsFrom:19600       #RegularizedStates:20417     \n",
      "93.4%         #RegularizedStatesWithTransitionsFrom:19600       #RegularizedStates:20417     \n",
      "93.41%        #RegularizedStatesWithTransitionsFrom:19600       #RegularizedStates:20417     \n",
      "93.43%        #RegularizedStatesWithTransitionsFrom:19600       #RegularizedStates:20417     \n",
      "93.44%        #RegularizedStatesWithTransitionsFrom:19600       #RegularizedStates:20417     \n",
      "93.45%        #RegularizedStatesWithTransitionsFrom:19600       #RegularizedStates:20417     \n",
      "93.47%        #RegularizedStatesWithTransitionsFrom:19600       #RegularizedStates:20417     \n",
      "93.48%        #RegularizedStatesWithTransitionsFrom:19600       #RegularizedStates:20417     \n",
      "93.5%         #RegularizedStatesWithTransitionsFrom:19600       #RegularizedStates:20417     \n",
      "93.51%        #RegularizedStatesWithTransitionsFrom:19600       #RegularizedStates:20417     \n",
      "93.52%        #RegularizedStatesWithTransitionsFrom:19600       #RegularizedStates:20417     \n",
      "93.54%        #RegularizedStatesWithTransitionsFrom:19600       #RegularizedStates:20417     \n",
      "93.55%        #RegularizedStatesWithTransitionsFrom:19600       #RegularizedStates:20417     \n",
      "93.57%        #RegularizedStatesWithTransitionsFrom:19600       #RegularizedStates:20417     \n",
      "98.34%        #RegularizedStatesWithTransitionsFrom:20400       #RegularizedStates:20597     \n",
      "98.35%        #RegularizedStatesWithTransitionsFrom:20400       #RegularizedStates:20597     \n",
      "98.37%        #RegularizedStatesWithTransitionsFrom:20400       #RegularizedStates:20597     \n",
      "\n",
      "Regularized Transitions:  1467124\n"
     ]
    }
   ],
   "source": [
    "explore_all_transitions()  # to find all existing state transitions in input trajectory set\n",
    "print ('\\n')\n",
    "obtain_transition_probabilities()  # to find probability of transitions and create transition graph\n",
    "print ('\\n')\n",
    "wedding_cake_probability_regularization() # to regularize transition graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
