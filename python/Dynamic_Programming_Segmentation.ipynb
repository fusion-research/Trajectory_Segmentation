{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Does This Notebook Do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs trajectory segmentation, where you can find a detailed description of segmentation process in section 3.4 of the following paper:\n",
    "* [Discovery of Driving Patterns by Trajectory Segmentation](https://arxiv.org/pdf/1804.08748.pdf)\n",
    "\n",
    "__Input__: transformed trajectory dataset, where each record of each trajectory has the following attributes:\n",
    "* `TripId`: id of trajectory (a string)\n",
    "* `TimeStep`: time step identifier for a record of a trajectory (an integer)\n",
    "* `ProbDissimilarity`: probability dissimilarity value for the current record of a trajectory (a float). This is the signal value for a record. \n",
    "* `Lat`: latitude coordinate of GPS (a float)\n",
    "* `Lng`: longitude coordinate of GPS (a float)\n",
    "* `Speed`: ground speed in km/h (a float)\n",
    "* `Acceleration`: acceleration in m/s^2 (a float)\n",
    "* `Heading`: change of heading with respect to previous time step in degrees (a float)\n",
    "\n",
    "Intput data must be specified in terms of a single csv file named as `ProbabilisticDissimilarities.csv`, and the input file must be placed inside `/prerequisiteFiles` directory. \n",
    "\n",
    "__Outputs__: this code generates a single csv file (inside the `/output` directory) that contains trajectory segmentation results. This file has the following attributes:\n",
    "* `TripId`: id of trajectory (a string)\n",
    "* `TimeStep`: time step identifier for a record of a trajectory (an integer)\n",
    "* `Speed`: ground speed in km/h (a float)\n",
    "* `Acceleration`: acceleration in m/s^2 (a float)\n",
    "* `HeadingChange`: change of heading with respect to previous time step in degrees (a float)\n",
    "* `Lat`: latitude coordinate of GPS (a float)\n",
    "* `Lng`: longitude coordinate of GPS (a float)\n",
    "* `PMD`: probabilistic movement dissimilarity (or probability dissimilarity) value for the current record of a trajectory (a float). This is the signal value for a record. \n",
    "* `StartOfSegment`: an indicator that specifies whether a given record is the start of a new segment or not. A value of 1 indicates that a record is start of a new segment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "e  = math.e\n",
    "pi = math.pi\n",
    "float_max_value = 1000000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tripTuple:\n",
    "    def __init__(self, time_step, speed, acceleration, heading, latitude, longitude):\n",
    "        self.speed = speed\n",
    "        self.acceleration = acceleration\n",
    "        self.heading = heading\n",
    "        self.lat = latitude\n",
    "        self.lng = longitude\n",
    "        self.time_step = time_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of Delta for all form of segments in given trajectory\n",
    "# delta_i(n_(i-1) , n_i - 1): the formula before (3) in paper! where n_(i-1) and n_i - 1 can be any possible pairs in trajectory!\n",
    "# Simply, here we have a window of dynamic size which scans whole trajectory! we will find the likelihood of that windows based on... \n",
    "# ...distribution of its points. Such distribution is a normal distribution and we have the assumption of independence of nodes ...\n",
    "# ... in order to make simplification in problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_mean_std(input):\n",
    "    mean = 0\n",
    "    for i in input:\n",
    "        mean += i\n",
    "    mean /= len(input)\n",
    "    \n",
    "    std = 0\n",
    "    for i in input:\n",
    "        std += (i-mean)**2\n",
    "    std = math.sqrt(std/len(input))\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln_of_normal_distribution(x, mean, std):\n",
    "    # res = ln(N(x, mean, std)) where N stands for normal distribution. \n",
    "    # N(x, mean, std) = (1/std * (2PI)^0.5) * exp(- (x - mean)^2 / (2 * std^2) )\n",
    "    try:\n",
    "        res = -1 * (math.log(std * math.sqrt(2 * pi)) + (math.pow(x-mean, 2)/(2 * math.pow(std, 2))))\n",
    "        return res\n",
    "    except: \n",
    "        return np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDelta(points): # vectorize calculations\n",
    "    delta = np.full((len(points)-1, len(points)), float_max_value)\n",
    "    \n",
    "    for i in range(len(points)-1):\n",
    "        for j in range(len(points)):\n",
    "            if (j-i+1) >= 2: # the length of a segment should be at least 2\n",
    "                mean,std = estimate_mean_std(points[i:j+1])\n",
    "                # get the ln value based on points in this segment and their corresponding distribution\n",
    "                value = 0\n",
    "                # The goal is minimizing the delta! So, when we have standard deviation = 0, this means no changes is observing in ...\n",
    "                # ...probabilistic dissimilarity values in range i to j! So, no change, no std! In other words, we have a uniform distribution...\n",
    "                # ...for this range! In this way, I decided to let the delta to be 0 in such situation. \n",
    "                if std!=0:\n",
    "                    mean = np.full(j+1-i, mean) # to prepare input for a vectorized  calculation\n",
    "                    std  = np.full(j+1-i, std) # to prepare input for a vectorized calculation\n",
    "                    v = points[i:j+1]\n",
    "                    # -1 * (math.log(std * math.sqrt(2 * pi)) + (math.pow(x-mean, 2)/(2 * math.pow(std, 2))))\n",
    "                    value = np.log(std * np.sqrt(2*pi)) + np.power(v-mean, 2)/(2*np.power(std, 2))\n",
    "                    value = np.sum(value)\n",
    "                delta[i][j] = value\n",
    "    return delta\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation Process as a Dynamic Programming Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamicProgramingSegmentation(points, Ns, delta):\n",
    "    # Finding optimal segmentation by having N_s as number of existing segments in given trajectory\n",
    "    # Here, we will find I_k(L) for all k = 1,2,...,N_s and for all L = 1,2,...,N\n",
    "    # The approach for finding these values is based on dynamic programming formula...\n",
    "    # ... which is provided as relation (4) in paper\n",
    "\n",
    "    # initialization of I\n",
    "    I = np.full((Ns, len(points)), float_max_value)\n",
    "    \n",
    "    # Initialization of Index\n",
    "    # In addition to minimum values, we need minimum indexes which show the best breaking points for segments\n",
    "    Index = np.full((Ns, len(points)), 0, dtype=int)\n",
    "    \n",
    "    # Now, we are going to find the optimal values\n",
    "    for k in range(Ns):\n",
    "        # Base case: this mean just having a single segment or I_1(L)\n",
    "        # Note: here k is 0 but based on paper formulation is 1\n",
    "        if k == 0:\n",
    "            # Here, the assumption is L>=2; but I considered this once that delta is calculated\n",
    "            for L in range(len(points)):\n",
    "                I[k][L] = delta[k][L]  # Note, segments of length 0 or 1 have delta value as +infinity!\n",
    "        \n",
    "\n",
    "        # Rest of the cases (having more than one segment): Well, here is the idea of dynamic programming\n",
    "        else:\n",
    "            # why (k*2 + 1): look at the printed picture! I have to have some lower level for L! when I have a couple of segments, ... \n",
    "            # ...the minimum criteria is I have a segment from 0 to 1. And the 2nd segment would be from 2! So, when k=1, the min length...\n",
    "            # ... for L should be 3 in order to have at least two separate segments. \n",
    "            for L in range(k*2+1, len(points)):\n",
    "                min_value = float_max_value\n",
    "                min_index = -1\n",
    "                # I. Why (L-1)? since I want to let the last segment be at least from L-1 to L. That is, the minimum length is 2!\n",
    "                # II. Look, here I have equality condition for L not just lower than! since L is index of upper loop and is precise. \n",
    "                # III. Why nk_1 = k*2? look at the last line of formula in left column of page 2 of paper. we have nk_1 as starting index ...\n",
    "                # ... of last segment. When have k = 1 or just want two segments, such index is at least 2! this means k*2. \n",
    "                for nk_1 in range(k*2, L):\n",
    "                    value = I[k-1][nk_1-1] + delta[nk_1][L]\n",
    "                    if value < min_value:\n",
    "                        min_value = value\n",
    "                        min_index  = nk_1\n",
    "                I[k][L]     = min_value\n",
    "                Index[k][L] = min_index\n",
    "                \n",
    "    return I, Index\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Description Length to Find Optimal Number of Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinimumDescriptionLength(points, Index, Ns):\n",
    "    # Here, the goal is to find the goodness of fit without any kind of over-fitting or a problem which have unseen data. \n",
    "    # We use the formula (7) in paper \"Optimal segmentation of signals and its application to image denoising and boundary feature extraction (2004)\" which is written based on a well-known research paper: \"modeling by shortest data description, 1978\"\t\t\n",
    "    MDL = 0\n",
    "\n",
    "    # 1. Calculation of first term\n",
    "    mle = 0\n",
    "\n",
    "    segment_end = len(points) - 1\n",
    "    segment_begin = -1\n",
    "    \n",
    "    for k in reversed(range(0, Ns)):\n",
    "        thisSegmentMLE = 0\n",
    "        segment_begin = Index[k][segment_end]\n",
    "        mean,std = estimate_mean_std(points[segment_begin:segment_end+1])\n",
    "        for i in range(segment_begin,segment_end):\n",
    "             thisSegmentMLE += ln_of_normal_distribution(points[i], mean, std)\n",
    "        mle += thisSegmentMLE\n",
    "        segment_end = segment_begin-1\n",
    "    \n",
    "    # there is a negative sign behind the ln in equation (7)\n",
    "    mle *= -1\n",
    "    MDL = mle\n",
    "\n",
    "    # 2. Calculation of second term\n",
    "    # r_k = #parameters for estimated distributions + k - 1\n",
    "    # Here, such number of parameters is 2*k since we have 2 parameters (mean and std) for every single estimated pdf\n",
    "    # Also, k = Ns\n",
    "    r_k = 2*Ns + Ns - 1\n",
    "    MDL += (r_k/2) * math.log(len(points)); # (r_k/2)*ln(N)\n",
    "\n",
    "    return MDL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trip_tuple:\n",
    "    def __init__(self, time_step, speed, acceleration, heading, latitude, longitude, pmd):\n",
    "        self.speed = float(speed)\n",
    "        self.acceleration = float(acceleration)\n",
    "        self.heading = float(heading)\n",
    "        self.lat = float(latitude)\n",
    "        self.lng = float(longitude)\n",
    "        self.time_step = int(time_step)\n",
    "        self.pmd = float(pmd) # probabilistic movement dissimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_process(trip_id, # trip id\n",
    "                         points,  # contains probabilistic dissimilarity values\n",
    "                         trip_points, # contains trip points\n",
    "                         max_number_of_segments, # the maximum number of segments that we allow\n",
    "                         writer # writer to print output \n",
    "                        ):\n",
    "    # 1. Calculation of Delta for all form of segments in given trajectory\n",
    "    print ('Building delta for {} ... '.format(trip_id), end='')\n",
    "    start = time.time()\n",
    "    delta = calculateDelta(points)\n",
    "    print ('completed in {:.1f} sec!'.format(time.time()-start))\n",
    "    \n",
    "    # 2. Optimization to find the best value of Ns\n",
    "    MDL = float_max_value\n",
    "    bestNs = -1\n",
    "    optimizedIndex = None\n",
    "    print ('Segmenting trajectory {} '.format(trip_id), end=''),\n",
    "    \n",
    "    start = time.time()\n",
    "    for Ns in range(1, max_number_of_segments+1):\n",
    "        # 3. Finding optimal segmentation by having N_s as number of existing segments in given trajectory\n",
    "        # In addition to minimum values, we need minimum indexes which show the best breaking points for segments\n",
    "        I,Index = dynamicProgramingSegmentation(points, Ns, delta)\n",
    "        mdl = MinimumDescriptionLength(points, Index, Ns)\n",
    "        if mdl < MDL:\n",
    "            MDL = mdl\n",
    "            bestNs = Ns\n",
    "            optimizedIndex = Index\n",
    "        print ('.', end='')\n",
    "    print (' completed in {:.1f} sec!'.format(time.time() - start))\n",
    "    \n",
    "    # 3. Using optimize I and Index to get the optimal segment boundaries\n",
    "    segmentPoints = set()\n",
    "    lastEndPoint = len(points)-1\n",
    "    for k in reversed(range(bestNs)):\n",
    "        segmentPoints.add(optimizedIndex[k][lastEndPoint])\n",
    "        lastEndPoint = optimizedIndex[k][lastEndPoint] - 1\n",
    "        \n",
    "    for i in range(0, len(trip_points)):\n",
    "        if i in segmentPoints:\n",
    "            writer.write('{},{},{},{},{},{},{},{},{}\\n'.format(trip_id, \n",
    "                                                       trip_points[i].time_step,\n",
    "                                                      trip_points[i].speed,\n",
    "                                                      trip_points[i].acceleration,\n",
    "                                                      trip_points[i].heading,\n",
    "                                                      trip_points[i].lat,\n",
    "                                                      trip_points[i].lng,\n",
    "                                                      trip_points[i].pmd,\n",
    "                                                      1))\n",
    "        else:\n",
    "            writer.write('{},{},{},{},{},{},{},{},{}\\n'.format(trip_id, \n",
    "                                                       trip_points[i].time_step,\n",
    "                                                      trip_points[i].speed,\n",
    "                                                      trip_points[i].acceleration,\n",
    "                                                      trip_points[i].heading,\n",
    "                                                      trip_points[i].lat,\n",
    "                                                      trip_points[i].lng,\n",
    "                                                      trip_points[i].pmd,\n",
    "                                                      0))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = open('output/segmentation_results.csv', 'w')\n",
    "writer.write('TripId,TimeStep,Speed,Acceleration,HeadingChange,Latitude,Longitude,PMD,StartOfSegment\\n')\n",
    "max_number_of_segments = 50\n",
    "n_trajectories = 0\n",
    "\n",
    "path = r'C:\\Users\\sobhan\\workspace\\TrajectorySegmentation'\n",
    "with open('prerequisiteFiles/ProbabilisticDissimilarities.csv', 'r') as reader:\n",
    "    header = True\n",
    "    trip_id = ''\n",
    "    points = [] # for probability dissimilarity values\n",
    "    trip_points = [] # for all trip points\n",
    "    \n",
    "    for line in reader:\n",
    "        if header:\n",
    "            header = False\n",
    "            continue\n",
    "        parts = line.replace('\\r','').replace('\\n','').split(',') # TripId,TimeStep,ProbDissimilarity,Lat,Lng,Speed,Acceleration,Heading\n",
    "        if parts[0] == trip_id:\n",
    "            points.append(float(parts[2]))\n",
    "            trip_points.append(trip_tuple(parts[1], # time step\n",
    "                                         parts[5], # speed\n",
    "                                         parts[6], # acceleration\n",
    "                                         parts[7], # heading change\n",
    "                                         parts[3], #latitude\n",
    "                                         parts[4], #longitude\n",
    "                                         parts[2] # pmd\n",
    "                                ))\n",
    "        else:\n",
    "            if trip_id != '':\n",
    "                # do segmentation\n",
    "                segmentation_process(trip_id, points, trip_points, max_number_of_segments, writer)\n",
    "                n_trajectories += 1\n",
    "            trip_id = parts[0]\n",
    "            points = [float(parts[2])]\n",
    "            trip_points = [trip_tuple(parts[1], # time step\n",
    "                                         parts[5], # speed\n",
    "                                         parts[6], # acceleration\n",
    "                                         parts[7], # heading change\n",
    "                                         parts[3], #latitude\n",
    "                                         parts[4], #longitude\n",
    "                                         parts[2] # pmd\n",
    "                                )\n",
    "                ]\n",
    "        \n",
    "    \n",
    "# do segmentation for the last trajectory\n",
    "segmentation_process(trip_id, points, trip_points, max_number_of_segments, writer)\n",
    "n_trajectories += 1\n",
    "writer.close()   \n",
    "print ('\\nDone with segmentation of {} trajectories!'.format(n_trajectories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "* Building delta is a preprocessing step prior to dynamic programming segmentation, which takes surprisingly longer than its Java implementation to run. \n",
    "\n",
    "* The python implmentation of segmentation takes way longer than its Java implmentation, altough both perform the same algorithm. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
